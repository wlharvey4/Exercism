# -*- mode:org; fill-column:79; -*-
#+Title:Exercism Exercises
#+Author:Pinecone062
#+Date:Last updated 2019-05-19 10:30
* Exercism Home
- https://github.com/exercism

** Exercism Readme

#+name:Exercism-Readme
#+begin_src text :tangle README.md
  # Welcome to Exercism

  This is the central point of contact for Exercism.

  ## Where to open issues

  The project is divided across many repositories.

  #### The website or product

  If you have any issues or questions regarding **the website
  (https://exercism.io)** please [open an issue in this
  repository](https://github.com/exercism/exercism/issues). To report
  errors in the website copy or submit fixes for typos or other
  improvements, please see the
  [exercism/website-copy](https://github.com/exercism/website-copy/issues)
  repository.

  #### The Command-Line Client (CLI)

  For problems with the **Command-Line Client (CLI)**, open an issue in
  [exercism/cli](https://github.com/exercism/cli/issues).

  #### Exercises in a particular programming language

  The exercises are all in separate, language-specific
  repositories. These repositories are tagged with the topic
  [`#exercism-track`](https://github.com/search?q=topic%3Aexercism-track+org%3Aexercism&type=Repositories). From
  there, search for the track (programming language) you are
  participating in.

  ,**Unsure? Open your issue here**

  If you aren't sure where to open it, then pick this repository. It's
  as good a starting point as any!

  ## Feeling uncomfortable?

  If you need to report a code of conduct violation, please email us at team@exercism.io.

  ## Where to find the code

  The code for the website lives in [exercism/website](http://github.com/exercism/website).

  The code for the old website is in this repository, in the
  [v1.exercism.io](https://github.com/exercism/exercism/tree/v1.exercism.io)
  branch.

  ## Who's behind Exercism?

  Read about our Team on the site: https://exercism.io/team
#+end_src

** Exercism CLI
- https://github.com/exercism/cli

To install manually, download the appropriate version of exercism based on your
processor architecture at the [[https://github.com/exercism/cli/releases/latest][releases page]], then extract the archive and put
the binary in your path.

Check the installed version with:

#+BEGIN_SRC sh :results output :exports both
exercism version
#+END_SRC

#+RESULTS:
: exercism version 3.0.11

In order to configure the CLI, paste in the following text into your terminal:
: exercism configure --token=b4b5ab41-b448-4762-a5ce-452ccd2eff08

 You should see a notification from the CLI that a configuration file has been
 written.

#+begin_src
You have configured the Exercism command-line client:

Config dir:                       ~/.config/exercism
Token:         (-t, --token)      b4b5ab41-b448-4762-a5ce-452ccd2eff08
Workspace:     (-w, --workspace)  <path-to>/Exercism
API Base URL:  (-a, --api)        https://api.exercism.io/v1
#+end_src

* Python Exercism Track
- http://exercism.io/languages/python
- https://github.com/exercism/python

The Python code in this repo is meant to follow the [[https://www.python.org/dev/peps/pep-0008/][PEP8 style guide]] (a
stylized version http://pep8.org).

This repo uses [[http://flake8.readthedocs.org/en/latest/][flake8]] with default settings to enforce the coding standard.

** Python README
#+name:Readme-Python-track
#+begin_src :tangle python/README.md :mkdirp yes
# Exercism Python Track

[![Build Status](https://travis-ci.org/exercism/python.svg?branch=master)](https://travis-ci.org/exercism/python) [![Requirements Status](https://pyup.io/repos/github/exercism/python/shield.svg)](https://pyup.io/repos/github/exercism/python/)
[![Join the chat at https://gitter.im/exercism/python](https://badges.gitter.im/exercism/python.svg)](https://gitter.im/exercism/python?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

Exercism exercises in Python


## Contributing Guide

Please see the [contributing guide](https://github.com/exercism/docs/blob/master/contributing-to-language-tracks/README.md)


## Working on the Exercises

We welcome both improvements to the existing exercises and new exercises.
A list of missing exercise can be found here: https://github.com/exercism/python/issues/417#issuecomment-366040062


### Conventions

- We use minimalistic stub files for all exercises ([#272](https://github.com/exercism/python/issues/272)).
- We use `unittest` (Python Standard Library) and no 3rd-party-framework.
- We use the parameter order `self.assertEqual(actual, expected)` ([#440](https://github.com/exercism/python/issues/440)).
- We use context managers (`with self.assertRaises(\<exception type\>):`) for testing for exceptions ([#477](https://github.com/exercism/python/issues/477)).
- We use an established utility method to confirm that expected exceptions contain a non-empty message. This method must be included for any test class with an exception-based test case ([#1080](https://github.com/exercism/python/issues/1080#issuecomment-442068539)).
- We use `assertIs(actual, True)` and `assertIs(actual, False)` rather than `assertTrue(actual)` or `assertFalse(actual)` ([#419](https://github.com/exercism/python/pull/419)).
- We use a comment string in the test file to reference the version of the exercise's `canonical-data.json` that tests were adapted from (wording can be found in: [#784](https://github.com/exercism/python/issues/784)).


### Testing

All exercises must be compatible with Python versions 2.7 and 3.4 upwards.

To test a single exercise (e.g., with Python 2.7):
```
python2.7 test/check-exercises.py [exercise-name]
```

To test all exercises (e.g., with Python 3):
```
python3 test/check-exercises.py
```


### Code Style

The Python code in this repo is meant to follow the [PEP8 style guide](https://www.python.org/dev/peps/pep-0008/) (a stylized version http://pep8.org).

This repo uses [flake8](http://flake8.readthedocs.org/en/latest/) with default settings to enforce the coding standard.


### CI build

This repo uses `travis-ci` in the following configuration: [travis.yml](https://github.com/exercism/python/blob/master/.travis.yml)

It will automatically check the code style, the problem configuration, and run the unittests with all supported Python versions.


## Pull Requests

We :heart: pull requests!
We even :sparkling_heart: them if they contain well written commit messages!

Please write the first line of your commit message in the following style:

```exercise-name: Change some things```

Please try to follow the [The seven rules of a great Git commit message](https://chris.beams.io/posts/git-commit/#seven-rules) like to capitalize the subject line and use the imperative mood. If there are more details to add, put those into the body of the commit message.

If you're interested, Tim Pope even has an [entire blog post](http://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html) on good commit messages.

If you're new to Git, take a look at [this short guide](https://github.com/exercism/docs/blob/master/contributing-to-language-tracks/README.md#git-basics).

## License
This repository uses the [MIT License](/LICENSE).
#+end_src

** Hello World Python

Write a function that returns the string "Hello, World!"

You can tell Python to run the ~pytest~ module (allowing the same command to be
used regardless of Python version):

: python -m pytest hello_world_test.py

Changed computer or want to re-download the exercise after updating to the
latest version? Use this command:

: exercism download --exercise=hello-world --track=python

: Downloaded to
: /usr/local/dev/programming/Exercism/python/hello-world

*** Solution to Hello World

#+name:hello_world.py
#+begin_src python :tangle python/hello-world/hello_world.py :mkdirp yes
def hello():
    return "Hello, World!"
#+end_src

*** Test for Hello World

#+name:Python-Hello-World-Test
#+begin_src python :tangle python/hello-world/hello_world_test.py :mkdirp yes
import unittest

import hello_world

# Tests adapted from `problem-specifications//canonical-data.json` @ v1.1.0

class HelloWorldTest(unittest.TestCase):
    def test_hello(self):
        self.assertEqual(hello_world.hello(), 'Hello, World!')


if __name__ == '__main__':
    unittest.main()
#+end_src

*** Run Tests on Hello World

#+begin_src sh :dir python/hello-world :results output :exports both
python3 -m pytest hello_world_test.py
#+end_src

** Two Fer Python
Two-fer or 2-fer is short for two for one. One for you and one for me.

: "One for X, one for me."

When X is a name or "you".

If the given name is "Alice", the result should be "One for Alice, one for me."
If no name is given, the result should be "One for you, one for me."

To run the tests:
: python3 -m pytest two_fer_test.py

*** Solution for Two Fer

#+name:Two-Fer-Solution
#+begin_src python :tangle python/two-fer/two_fer.py :mkdirp yes
def two_fer(name="you"):
    return "One for " + name + ", one for me."
#+end_src

#+begin_src sh :dir python/two-fer :results output
python3 -m pytest two_fer_test.py
#+end_src

#+RESULTS:
: ============================= test session starts ==============================
: platform darwin -- Python 3.7.3, pytest-4.4.1, py-1.8.0, pluggy-0.9.0
: rootdir: /usr/local/dev/programming/Exercism/python/two-fer
: collected 3 items
: 
: two_fer_test.py ...                                                      [100%]
: 
: =========================== 3 passed in 0.01 seconds ===========================

*** Test for Two Fer

#+name:Python-Two-Fer-Test
#+begin_src python :tangle python/two-fer/two_fer_test.py :mkdirp yes
import unittest

from two_fer import two_fer


# Tests adapted from `problem-specifications//canonical-data.json` @ v1.2.0

class TwoFerTest(unittest.TestCase):
    def test_no_name_given(self):
        self.assertEqual(two_fer(), 'One for you, one for me.')

    def test_a_name_given(self):
        self.assertEqual(two_fer("Alice"), "One for Alice, one for me.")

    def test_another_name_given(self):
        self.assertEqual(two_fer("Bob"), "One for Bob, one for me.")


if __name__ == '__main__':
    unittest.main()
#+end_src

*** Run Tests on Two Fer

#+begin_src sh :dir python/two-fer :results output :exports both
python3 -m pytest two_fer_test.py
#+end_src

#+RESULTS:
: ============================= test session starts ==============================
: platform darwin -- Python 3.7.3, pytest-4.0.2, py-1.7.0, pluggy-0.8.0
: rootdir: /Users/pine/Dev/Programming/Languages/Exercism/python/two-fer, inifile:
: collected 3 items
: 
: two_fer_test.py ...                                                      [100%]
: 
: =========================== 3 passed in 0.03 seconds ===========================

** High Scores
:PROPERTIES:
:level:    easy
:END:

*** Task for High Scores
Manage a game player's High Score list.

Your task is to build a high-score component of the classic Frogger game, one
of the highest selling and addictive games of all time, and a classic of the
arcade era.  Your task is to write methods that return the highest score from
the list, the last added score, the three highest scores, and a report on the
difference between the last and the highest scores.

*** Readme for High Scores

#+name:High_Scores_Python_Readme
#+begin_src text :tangle python/high-scores/README.md :mkdirp yes
  # High Scores

  Manage a game player's High Score list.

  Your task is to build a high-score component of the classic Frogger
  game, one of the highest selling and addictive games of all time, and
  a classic of the arcade era. Your task is to write methods that return
  the highest score from the list, the last added score, the three
  highest scores, and a report on the difference between the last and
  the highest scores.

  ## Submitting Exercises

  Note that, when trying to submit an exercise, make sure the solution
  is in the `exercism/python/<exerciseName>` directory.

  For example, if you're submitting `bob.py` for the Bob exercise, the
  submit command would be something like `exercism submit
  <path_to_exercism_dir>/python/bob/bob.py`.


  For more detailed information about running tests, code style and linting,
  please see the [help page](http://exercism.io/languages/python).

  ## Source

  Tribute to the eighties' arcade game Frogger

  ## Submitting Incomplete Solutions
  It's possible to submit an incomplete solution so you can see how others have completed the exercise.

#+end_src

*** Solution to High Scores

#+name:High_Scores_Python
#+begin_src python :tangle python/high-scores/high_scores.py :mkdirp yes
class HighScores(object):
    def __init__(self, scores):
        self.scores = scores

    def latest(self):
        return self.scores[-1]

    def personal_best(self):
        best = 0
        for score in self.scores:
            if score > best:
                best = score

        return best

    def personal_top(self):
        pt = self.scores[:]
        pt.sort(reverse=True)
        return pt[:3]

    def report(self):
        latest = self.scores[-1]
        best = self.personal_best()
        report = f"Your latest score was {latest}. "
        if latest == best:
            report += f"That's your personal best!"
        else:
            report += f"That's {best - latest} short of your personal best!"

        return report
#+end_src

*** Tests for High Scores

#+name:High_Scores_Python_Test
#+begin_src python :tangle python/high-scores/high_scores_test.py :mkdirp yes
import unittest

from high_scores import HighScores


# Tests adapted from `problem-specifications//canonical-data.json` @ v2.0.0


class HighScoreTest(unittest.TestCase):
    def test_list_of_scores(self):
        scores = [30, 50, 20, 70]
        expected = [30, 50, 20, 70]
        self.assertEqual(HighScores(scores).scores, expected)

    def test_latest_score(self):
        scores = [100, 0, 90, 30]
        expected = 30
        self.assertEqual(HighScores(scores).latest(), expected)

    def test_personal_best(self):
        scores = [40, 100, 70]
        expected = 100
        self.assertEqual(HighScores(scores).personal_best(), expected)

    def test_personal_top(self):
        scores = [50, 30, 10]
        expected = [50, 30, 10]
        self.assertEqual(HighScores(scores).personal_top(), expected)

    def test_personal_top_highest_to_lowest(self):
        scores = [20, 10, 30]
        expected = [30, 20, 10]
        self.assertEqual(HighScores(scores).personal_top(), expected)

    def test_personal_top_when_there_is_a_tie(self):
        scores = [40, 20, 40, 30]
        expected = [40, 40, 30]
        self.assertEqual(HighScores(scores).personal_top(), expected)

    def test_personal_top_when_there_are_less_than_3(self):
        scores = [30, 70]
        expected = [70, 30]
        self.assertEqual(HighScores(scores).personal_top(), expected)

    def test_personal_top_when_there_is_only_one(self):
        scores = [40]
        expected = [40]
        self.assertEqual(HighScores(scores).personal_top(), expected)

    def test_personal_top_from_a_long_list(self):
        scores = [10, 30, 90, 30, 100, 20, 10, 0, 30, 40, 40, 70, 70]
        expected = [100, 90, 70]
        self.assertEqual(HighScores(scores).personal_top(), expected)

    def test_message_for_new_personal_best(self):
        scores = [20, 40, 0, 30, 70]
        expected = "Your latest score was 70. That's your personal best!"
        self.assertEqual(HighScores(scores).report(), expected)

    def test_message_when_latest_score_is_not_the_highest_score(self):
        scores = [20, 100, 0, 30, 70]
        expected = (
            "Your latest score was 70. That's 30 short of your personal best!"
        )
        self.assertEqual(HighScores(scores).report(), expected)

    def test_message_for_repeated_personal_best(self):
        scores = [20, 70, 50, 70, 30]
        expected = (
            "Your latest score was 30. That's 40 short of your personal best!"
        )
        self.assertEqual(HighScores(scores).report(), expected)


if __name__ == "__main__":
    unittest.main()
#+end_src

*** Test High Score

#+name:Test_High_Score_Python
#+begin_src sh :dir python/high-scores :results output :exports results
python3 -m pytest high_scores_test.py
#+end_src

#+RESULTS: Test_High_Score_Python
: ============================= test session starts ==============================
: platform darwin -- Python 3.7.3, pytest-4.0.2, py-1.7.0, pluggy-0.8.0
: rootdir: /Users/pine/Dev/Programming/Languages/Exercism/python/high-scores, inifile:
: collected 12 items
: 
: high_scores_test.py ............                                         [100%]
: 
: ========================== 12 passed in 0.02 seconds ===========================

* Exercism Makefile

#+name:Exercism-Makefile
#+begin_src makefile :tangle Makefile
BASE_DIR := /usr/local/dev/programming/Languages/Exercism
LANGUAGES = python

.phony : dist-clean
dist-clean :
	cd $(BASE_DIR) && rm -vrf $(LANGUAGES) Exercism.html README.md

.phony : world-clean
world-clean : dist-clean
	rm Makefile

#+end_src

* Export Settings                                                  :noexport:
** HTML Export
#+options: html-link-use-abs-url:nil html-postamble:auto html-preamble:t
#+options: html-scripts:t html-style:t html5-fancy:t tex:t
#+html_doctype: html5
#+html_container: div
#+description:Exercises from Exercism.io Python language
#+keywords:exercism.io exercises Python
#+html_link_home:
#+html_link_up:
#+html_mathjax:
#+html_head:
#+html_head_extra:
#+infojs_opt:
#+creator: <a href="https://www.gnu.org/software/emacs/">Emacs</a> 26.1 (<a href="https://orgmode.org">Org</a> mode 9.2.2)
#+latex_header:

* Local Variables                                                  :noexport:
# Local Variables:
# time-stamp-pattern:"8/^\\#\\+[dD]ate:Last updated %:y-%02m-%02d %02H:%02M$"
# End:
